{"cells":[{"cell_type":"markdown","metadata":{"id":"AoxOjIlOImwx"},"source":["# Build a Gym Environment\n","\n","This notebook is inspired to the Stable Baselines3 tutorial available at [https://github.com/araffin/rl-tutorial-jnrr19](https://github.com/araffin/rl-tutorial-jnrr19).\n","\n","\n","## Introduction\n","\n","In this notebook, we will learn how to build a customized environment with **Gymnasium**.\n","\n","### Links\n","\n","Gymnasium Github: [https://github.com/Farama-Foundation/Gymnasium](https://github.com/Farama-Foundation/Gymnasium)\n","\n","Gymnasium Documentation: [https://gymnasium.farama.org/index.html](https://gymnasium.farama.org/index.html#)\n","\n","Stable Baselines 3 Github:[https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n","\n","Stable Baseline 3 Documentation: [https://stable-baselines3.readthedocs.io/en/master/](https://stable-baselines3.readthedocs.io/en/master/)\n","\n","## Install Gymnasium and Stable Baselines3 Using Pip"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17756,"status":"ok","timestamp":1708270873681,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"Sp8rSS4DIhEV","outputId":"20961e80-e268-4d16-943c-cec6f3bbc0c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: renderlab in /usr/local/lib/python3.10/dist-packages (0.1.20230421184216)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from renderlab) (1.0.3)\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from renderlab) (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (0.0.4)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.66.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.31.0)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.1.10)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.31.6)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.4.9)\n","Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->renderlab) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy->renderlab) (67.7.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2024.2.2)\n","Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.2.1)\n","Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n","Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.1.0+cu121)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.2)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.0)\n","Requirement already satisfied: shimmy[atari]~=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.3.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n","Requirement already satisfied: autorom[accept-rom-license]~=0.6.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.6.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n","Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (0.6.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.9.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n","Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]~=1.3.0->stable-baselines3[extra]) (0.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.60.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.5.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.1.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.1.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"]}],"source":["!pip install gymnasium\n","!pip install renderlab  #For rendering\n","!pip install stable-baselines3[extra]"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1708270873681,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"fOrkWxmlviA4","outputId":"36172a22-0396-46c2-d522-bd462505721e"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.29.1\n","2.2.1\n"]}],"source":["import numpy as np\n","\n","import gymnasium as gym\n","from gymnasium.spaces import Box\n","from gymnasium.envs.registration import register\n","import stable_baselines3\n","from stable_baselines3 import PPO, DDPG, SAC\n","from stable_baselines3.common.env_checker import check_env\n","\n","print(gym.__version__)\n","print(stable_baselines3.__version__)"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1708270873681,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"5ToqdPSfviA5"},"outputs":[],"source":["def evaluate(env, policy, gamma=1., num_episodes=100):\n","    \"\"\"\n","    Evaluate a RL agent\n","    :param env: (Env object) the Gym environment\n","    :param policy: (BasePolicy object) the policy in stable_baselines3\n","    :param gamma: (float) the discount factor\n","    :param num_episodes: (int) number of episodes to evaluate it\n","    :return: (float) Mean reward for the last num_episodes\n","    \"\"\"\n","    all_episode_rewards = []\n","    for i in range(num_episodes): # iterate over the episodes\n","        episode_rewards = []\n","        done = False\n","        discounter = 1.\n","        obs, _ = env.reset()\n","        while not done: # iterate over the steps until termination\n","            action, _ = policy.predict(obs)\n","            obs, reward, terminated, truncated, _ = env.step(action)\n","            done = terminated or truncated\n","            episode_rewards.append(reward * discounter) # compute discounted reward\n","            discounter *= gamma\n","\n","        all_episode_rewards.append(sum(episode_rewards))\n","\n","    mean_episode_reward = np.mean(all_episode_rewards)\n","    std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n","    print(\"Mean reward:\", mean_episode_reward,\n","          \"Std reward:\", std_episode_reward,\n","          \"Num episodes:\", num_episodes)\n","\n","    return mean_episode_reward, std_episode_reward"]},{"cell_type":"markdown","metadata":{"id":"yitpwwp3viA7"},"source":["## The Minigolf Environment\n","\n","The `Minigolf` environment models a simple problem in which the agent has to hit a ball on a green using a putter in order to reach the hole with the minimum amount of moves.\n","\n","* The green is characterized by a **friction** $f$ that is selected uniformly random at the beginning of each episode in the interval `[0.065, 0.196]` and does not change during the episode.\n","* The **position** of the ball is represented by a unidimensional variable $x_t$ that is initialized uniformly random in the interval `[1,20]`. The observation is made of the pair $s_t = (x_t,f)$.\n","* The **action** $a_t$ is the force applied to the putter and has to be bounded in the interval `[1e-5,5]`. Before being applied the action is subject to a Gaussian noise, so that the actual action $u_t$ applied is given by:\n","\n","$\n","u_t = a_t + \\epsilon \\qquad \\text{where} \\qquad \\epsilon \\sim \\mathcal{N}(0,\\sigma^2),\n","$\n","where $\\sigma =0.1$. The movement of the ball is governed by the kinematic law:\n","\n","$\n","x_{t+1} = x_{t} - v_t \\tau_t + \\frac{1}{2} d \\tau_t^2\n","$\n","\n","where:\n","* $v_t$ is the velocity computed as $v_t = u_t l$,\n","* $d$ is the deceleration computed as $d = \\frac{5}{7} fg$,\n","* $\\tau_t$ is the time interval computed as $\\tau_t = \\frac{v_t}{d}$.\n","\n","The remaining constants are the putter length $l = 1$ and the gravitational acceleration $g=9.81$. The **episode** terminates when the next state is such that the ball enters or surpasses (without entering) the hole. The **reward** is `-1` at every step and `-100` if the ball surpasses the hole. To check whether the ball will not reach, enter, or surpass the hole, refer to the following condition:\n","\n","\\begin{align*}\n","&v_t < v_{\\min} \\implies \\text{ball does not reach the hole} \\\\\n","&v_t > v_{\\max} \\implies \\text{ball surpasses the hole} \\\\\n","&\\text{otherwise} \\implies \\text{ball enters the hole}\n","\\end{align*}\n","\n","where\n","\n","\\begin{align*}\n","& v_{\\min} = \\sqrt{\\frac{10}{7} fgx_t}\n","& v_{\\max} = \\sqrt{ \\frac{g(2 h - \\rho)^2}{2r} + v_{\\min}^2},\n","\\end{align*}\n","where $h = 0.1$ is the hole size and $\\rho = 0.02135$ is the ball radius.\n","\n","\n","**References**\n","\n","Penner, A. R. \"The physics of putting.\" Canadian Journal of Physics 80.2 (2002): 83-96."]},{"cell_type":"markdown","metadata":{"id":"6_QiBx81viA8"},"source":["## Exercise 1\n","\n","Complete the constructor `__init__`, methods `reset` and `step` based on the environment description provided above."]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1708270873682,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"y1JZ2BDoviA8"},"outputs":[],"source":["# agent has to hit the ball with the minimum number of moves. f - friction value (random at the beginning, then fixed);\n","# state = (pos, frict); # action - bounded force with some Gaussian noise -> transition model is the kenematic law\n","\n","class Minigolf(gym.Env):\n","    \"\"\"\n","    The Minigolf problem.\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(Minigolf, self).__init__()\n","\n","        # Constants\n","        self.min_pos, self.max_pos = 1.0, 20.0\n","        self.min_action, self.max_action = 1e-5, 5.0\n","        self.min_friction, self.max_friction = 0.065, 0.196\n","        self.putter_length = 1.0\n","        self.hole_size = 0.10\n","        self.sigma_noise = 0.1\n","        self.ball_radius = 0.02135\n","\n","\n","        # Instance the spaces\n","        low = np.array([self.min_pos, self.min_friction])\n","        high = np.array([self.max_pos, self.max_friction])\n","\n","        self.action_space = Box(low=self.min_action,\n","                                high=self.max_action,\n","                                shape=(1,),\n","                                dtype=np.float32)\n","\n","        self.observation_space = Box(low=low,\n","                                     high=high,\n","                                     shape=(2,),\n","                                     dtype=np.float32)\n","\n","\n","    def step(self, action):\n","\n","        #Retrieve the state components\n","        x, friction = self.state\n","\n","        # Clip the action within the allowed range\n","        action = np.clip(action, self.min_action, self.max_action)\n","\n","        # TODO Add noise to the action\n","        u = action + np.random.normal(0, self.sigma_noise)\n","        # TODO Compute the speed\n","        v = self.putter_length * u\n","        v = np.array(v).ravel().item()# make sure it is a value\n","\n","        # Compute the speed limits\n","        v_min = np.sqrt(10 / 7 * friction * 9.81 * x)\n","        v_max = np.sqrt((2 * self.hole_size - self.ball_radius) ** 2 \\\n","                        * (9.81 / (2 * self.ball_radius)) + v_min ** 2)\n","\n","        # TODO Compute the deceleration\n","        d = 5 / 7 * 9.81 * friction\n","        # TODO Compute the time interval\n","        tau = v / d\n","        # TODO Update the position\n","        x -= v * tau + 1 / 2 * d * tau ** 2\n","        # Clip the position\n","        x = np.clip(x, self.min_pos, self.max_pos)\n","\n","        # TODO Compute the reward and episode termination (done)\n","        reward = 0\n","        done = False\n","        if v < v_min:\n","           reward = -1\n","        elif v > v_max:\n","           reward = -100\n","           done = True\n","        else:\n","           done = True\n","        self.state = np.array([x, friction]).astype(np.float32)\n","\n","        return self.state, reward, done, False, {}\n","\n","\n","    def reset(self, seed=None):\n","\n","        # TODO Random generation of initial position and friction\n","        x, friction = np.random.uniform(self.min_pos, self.max_pos), np.random.uniform(self.min_friction, self.max_friction)\n","        self.state = np.array([x, friction]).astype(np.float32)\n","\n","        return self.state, {}"]},{"cell_type":"markdown","metadata":{"id":"2scoVGi0x-7U"},"source":["### Solution\n","```python\n","import numpy as np\n","from gymnasium.spaces import Box\n","\n","class Minigolf(gym.Env):\n","    \"\"\"\n","    The Minigolf problem.\n","\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(Minigolf, self).__init__()\n","\n","        # Constants\n","        self.min_pos, self.max_pos = 1.0, 20.0\n","        self.min_action, self.max_action = 1e-5, 5.0\n","        self.min_friction, self.max_friction = 0.065, 0.196\n","        self.putter_length = 1.0\n","        self.hole_size = 0.10\n","        self.sigma_noise = 0.1\n","        self.ball_radius = 0.02135\n","\n","\n","        # Instance the spaces\n","        low = np.array([self.min_pos, self.min_friction])\n","        high = np.array([self.max_pos, self.max_friction])\n","\n","        self.action_space = Box(low=self.min_action,\n","                                high=self.max_action,\n","                                shape=(1,),\n","                                dtype=np.float32)\n","\n","        self.observation_space = Box(low=low,\n","                                     high=high,\n","                                     shape=(2,),\n","                                     dtype=np.float32)\n","\n","\n","    def step(self, action):\n","\n","        #Retrieve the state components\n","        x, friction = self.state\n","\n","        # Clip the action within the allowed range\n","        action = np.clip(action, self.min_action, self.max_action)\n","\n","        # Add noise to the action\n","        noisy_action = action + np.random.randn() * self.sigma_noise\n","\n","        # Compute the speed\n","        v = noisy_action * self.putter_length\n","        v = np.array(v).ravel().item()\n","\n","        # Compute the speed limits\n","        v_min = np.sqrt(10 / 7 * friction * 9.81 * x)\n","        v_max = np.sqrt((2 * self.hole_size - self.ball_radius) ** 2 \\\n","                        * (9.81 / (2 * self.ball_radius)) + v_min ** 2)\n","\n","        # Compute the deceleration\n","        deceleration = 5 / 7 * friction * 9.81\n","\n","        # Compute the time interval\n","        t = v / deceleration\n","\n","        # Update the state and clip\n","        x = x - v * t + 0.5 * deceleration * t ** 2\n","        x = np.clip(x, self.min_pos, self.max_pos)\n","\n","        # Compute the reward and episode termination\n","        reward = 0.\n","        done = True\n","\n","        if v < v_min:\n","            reward = -1.\n","            done = False\n","        elif v > v_max:\n","            reward = -100.\n","\n","        self.state = np.array([x, friction]).astype(np.float32)\n","\n","        return self.state, reward, done, False, {}\n","\n","\n","    def reset(self, seed=None):\n","\n","        # Random generation of initial position and friction\n","        x, friction = np.random.uniform(low=[self.min_pos, self.min_friction],\n","                                        high=[self.max_pos, self.max_friction])\n","\n","        self.state = np.array([x, friction]).astype(np.float32)\n","\n","        return self.state, {}\n"]},{"cell_type":"markdown","metadata":{"id":"m7FkSAMFviA9"},"source":["To be able to instance the environment with `gym.make`, we need to register the environment"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1708270873682,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"DG9IBUduviA9","outputId":"e889339e-580d-4e53-f294-ffe93f210aaa"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment Minigolf-v1 already in registry.\u001b[0m\n","  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n","\n"]}],"source":["register(\n","    id=\"Minigolf-v1\",\n","    entry_point=\"__main__:Minigolf\",\n","    max_episode_steps=20,# terminate everything after 20 steps\n","    reward_threshold=0,\n",")"]},{"cell_type":"markdown","metadata":{"id":"dZGORKvzviA-"},"source":["### Validate the environment\n","\n","Stable Baselines3 provides a [helper](https://stable-baselines3.readthedocs.io/en/master/common/env_checker.html) to check that our environment complies with the Gym interface."]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1708270873682,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"iUcLpum-viA-","outputId":"4dae4421-1838-4648-d2c5-11e0d2499b88"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:441: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n","  warnings.warn(\n","\n"]}],"source":["env = Minigolf()\n","\n","# If the environment don't follow the interface, an error will be thrown\n","check_env(env, warn=True)"]},{"cell_type":"markdown","metadata":{"id":"yU1GzuXMviA-"},"source":["## Evaluate some simple Policies\n","\n","* **Do-nothing policy**: a policy plays the zero action.\n","\n","$$\n","\\pi(s) = 0\n","$$\n","\n","\n","* **Max-action policy**: a policy that plays the maximum available actions.\n","\n","$$\n","\\pi(s) = +\\infty\n","$$\n","\n","\n","* **Zero-mean Gaussian policy**: a policy that selects the action sampled from a Gaussian policy with zero mean and variance $\\sigma^2=1$\n","\n","$$\n","\\pi(a|s) = \\mathcal{N}(0,\\sigma^2)\n","$$"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1708270873682,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"uWLRtOzRviA_"},"outputs":[],"source":["class DoNothingPolicy():\n","\n","    def predict(self, obs):\n","        return 0, obs\n","\n","\n","class MaxActionPolicy():\n","\n","    def predict(self, obs):\n","        return np.inf, obs\n","\n","\n","class ZeroMeanGaussianPolicy():\n","\n","    def predict(self, obs):\n","        return np.random.randn(), obs"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454,"status":"ok","timestamp":1708270874125,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"D7zdbEzdviA_","outputId":"9e53c408-5a69-4ca7-9f02-450889e6011a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:181: DeprecationWarning: \u001b[33mWARN: Current gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n","  logger.deprecation(\n","\n"]},{"name":"stdout","output_type":"stream","text":["Mean reward: -20.0 Std reward: 0.0 Num episodes: 100\n","Mean reward: -86.36 Std reward: 3.502250935635769 Num episodes: 100\n","Mean reward: -16.43 Std reward: 0.6080694737022118 Num episodes: 100\n"]}],"source":["env = gym.make(\"Minigolf-v1\")\n","\n","do_nothing_policy = DoNothingPolicy()\n","\n","max_action_policy = MaxActionPolicy()\n","\n","gauss_policy = ZeroMeanGaussianPolicy()\n","\n","\n","do_nothing_mean, do_nothing_std = evaluate(env, do_nothing_policy)\n","max_action_mean, max_action_std = evaluate(env, max_action_policy)\n","gauss_policy_mean, gauss_policy_std = evaluate(env, gauss_policy)"]},{"cell_type":"markdown","metadata":{"id":"4qoWWQKeviA_"},"source":["## Train PPO, DDPG, and SAC\n","\n","We now train three algorithms suitable for environments with continuous actions: [Proximal Policy Optimization](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html), [Deep Deterministic Policy Gradient](https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html), and [Soft Actor Critic](https://stable-baselines3.readthedocs.io/en/master/modules/sac.html)."]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ae12c35a83124142b2b0c6e0c8b7462e","0152e8576ccb47fd94b0bbf9fa97fbfd","dca3cf7858494cdca59280e58e6ec4c7","a1e21b38df3f40aab176bf252de36ed0","ed9bea39299f4b2a99c145b3d6abdf83","0307778242b041df9f27210cb392e9a4"]},"executionInfo":{"elapsed":1056700,"status":"ok","timestamp":1708271930798,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"JICM9YhjviBA","outputId":"a7a4f3f5-d674-469e-959e-27b3ff9658f0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae12c35a83124142b2b0c6e0c8b7462e","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Using cuda device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Using cuda device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Using cuda device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","PPO\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 13.1        |\n","|    ep_rew_mean          | -14.3       |\n","| time/                   |             |\n","|    fps                  | 386         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 21          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.013472047 |\n","|    clip_fraction        | 0.108       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.46       |\n","|    explained_variance   | 0.0387      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 121         |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0045     |\n","|    std                  | 1.04        |\n","|    value_loss           | 141         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 8.26        |\n","|    ep_rew_mean          | -9.31       |\n","| time/                   |             |\n","|    fps                  | 417         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 39          |\n","|    total_timesteps      | 16384       |\n","| train/                  |             |\n","|    approx_kl            | 0.008266924 |\n","|    clip_fraction        | 0.0711      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.4        |\n","|    explained_variance   | 0.0504      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 13.7        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.00845    |\n","|    std                  | 0.973       |\n","|    value_loss           | 137         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 4.9         |\n","|    ep_rew_mean          | -3.9        |\n","| time/                   |             |\n","|    fps                  | 432         |\n","|    iterations           | 12          |\n","|    time_elapsed         | 56          |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.005973646 |\n","|    clip_fraction        | 0.0395      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.33       |\n","|    explained_variance   | 0.0185      |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 7.49        |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.00415    |\n","|    std                  | 0.905       |\n","|    value_loss           | 204         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 4.5         |\n","|    ep_rew_mean          | -4.5        |\n","| time/                   |             |\n","|    fps                  | 430         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 76          |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.009743035 |\n","|    clip_fraction        | 0.0604      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.22       |\n","|    explained_variance   | 0.00483     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 192         |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.00864    |\n","|    std                  | 0.808       |\n","|    value_loss           | 241         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 3.02        |\n","|    ep_rew_mean          | -3.02       |\n","| time/                   |             |\n","|    fps                  | 429         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 95          |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.012466531 |\n","|    clip_fraction        | 0.111       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -1.09       |\n","|    explained_variance   | 0.00342     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 143         |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.0121     |\n","|    std                  | 0.705       |\n","|    value_loss           | 159         |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 2.28        |\n","|    ep_rew_mean          | -4.28       |\n","| time/                   |             |\n","|    fps                  | 425         |\n","|    iterations           | 24          |\n","|    time_elapsed         | 115         |\n","|    total_timesteps      | 49152       |\n","| train/                  |             |\n","|    approx_kl            | 0.026486471 |\n","|    clip_fraction        | 0.171       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.919      |\n","|    explained_variance   | 0.00141     |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 75          |\n","|    n_updates            | 230         |\n","|    policy_gradient_loss | -0.0176     |\n","|    std                  | 0.592       |\n","|    value_loss           | 133         |\n","-----------------------------------------\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dca3cf7858494cdca59280e58e6ec4c7","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["DDPG\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.9      |\n","|    ep_rew_mean     | -1.9     |\n","| time/              |          |\n","|    episodes        | 1024     |\n","|    fps             | 153      |\n","|    time_elapsed    | 77       |\n","|    total_timesteps | 11920    |\n","| train/             |          |\n","|    actor_loss      | 17.1     |\n","|    critic_loss     | 3.89     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 11822    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 4.39     |\n","|    ep_rew_mean     | -3.46    |\n","| time/              |          |\n","|    episodes        | 2048     |\n","|    fps             | 151      |\n","|    time_elapsed    | 135      |\n","|    total_timesteps | 20473    |\n","| train/             |          |\n","|    actor_loss      | 1.4      |\n","|    critic_loss     | 0.299    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 20375    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.95     |\n","|    ep_rew_mean     | -0.95    |\n","| time/              |          |\n","|    episodes        | 3072     |\n","|    fps             | 151      |\n","|    time_elapsed    | 149      |\n","|    total_timesteps | 22575    |\n","| train/             |          |\n","|    actor_loss      | 1.35     |\n","|    critic_loss     | 0.17     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 22477    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.87     |\n","|    ep_rew_mean     | -0.87    |\n","| time/              |          |\n","|    episodes        | 4096     |\n","|    fps             | 150      |\n","|    time_elapsed    | 163      |\n","|    total_timesteps | 24538    |\n","| train/             |          |\n","|    actor_loss      | 1.18     |\n","|    critic_loss     | 9.67     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 24440    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.8      |\n","|    ep_rew_mean     | -0.8     |\n","| time/              |          |\n","|    episodes        | 5120     |\n","|    fps             | 149      |\n","|    time_elapsed    | 176      |\n","|    total_timesteps | 26454    |\n","| train/             |          |\n","|    actor_loss      | 0.777    |\n","|    critic_loss     | 1.3      |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 26356    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.88     |\n","|    ep_rew_mean     | -0.88    |\n","| time/              |          |\n","|    episodes        | 6144     |\n","|    fps             | 149      |\n","|    time_elapsed    | 189      |\n","|    total_timesteps | 28343    |\n","| train/             |          |\n","|    actor_loss      | 0.612    |\n","|    critic_loss     | 11       |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 28245    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.75     |\n","|    ep_rew_mean     | -0.75    |\n","| time/              |          |\n","|    episodes        | 7168     |\n","|    fps             | 149      |\n","|    time_elapsed    | 202      |\n","|    total_timesteps | 30203    |\n","| train/             |          |\n","|    actor_loss      | 0.87     |\n","|    critic_loss     | 1.43     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 30106    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.7      |\n","|    ep_rew_mean     | -0.7     |\n","| time/              |          |\n","|    episodes        | 8192     |\n","|    fps             | 148      |\n","|    time_elapsed    | 215      |\n","|    total_timesteps | 32059    |\n","| train/             |          |\n","|    actor_loss      | 0.554    |\n","|    critic_loss     | 0.217    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 31962    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.83     |\n","|    ep_rew_mean     | -0.83    |\n","| time/              |          |\n","|    episodes        | 9216     |\n","|    fps             | 148      |\n","|    time_elapsed    | 228      |\n","|    total_timesteps | 33913    |\n","| train/             |          |\n","|    actor_loss      | 0.493    |\n","|    critic_loss     | 0.155    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 33815    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.79     |\n","|    ep_rew_mean     | -0.79    |\n","| time/              |          |\n","|    episodes        | 10240    |\n","|    fps             | 148      |\n","|    time_elapsed    | 241      |\n","|    total_timesteps | 35756    |\n","| train/             |          |\n","|    actor_loss      | 0.655    |\n","|    critic_loss     | 0.225    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 35658    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.84     |\n","|    ep_rew_mean     | -0.84    |\n","| time/              |          |\n","|    episodes        | 11264    |\n","|    fps             | 147      |\n","|    time_elapsed    | 254      |\n","|    total_timesteps | 37614    |\n","| train/             |          |\n","|    actor_loss      | 0.382    |\n","|    critic_loss     | 1.31     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 37516    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.82     |\n","|    ep_rew_mean     | -0.82    |\n","| time/              |          |\n","|    episodes        | 12288    |\n","|    fps             | 147      |\n","|    time_elapsed    | 268      |\n","|    total_timesteps | 39459    |\n","| train/             |          |\n","|    actor_loss      | 0.384    |\n","|    critic_loss     | 0.158    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 39361    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.81     |\n","|    ep_rew_mean     | -0.81    |\n","| time/              |          |\n","|    episodes        | 13312    |\n","|    fps             | 147      |\n","|    time_elapsed    | 280      |\n","|    total_timesteps | 41305    |\n","| train/             |          |\n","|    actor_loss      | 0.342    |\n","|    critic_loss     | 0.115    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 41207    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.72     |\n","|    ep_rew_mean     | -0.72    |\n","| time/              |          |\n","|    episodes        | 14336    |\n","|    fps             | 147      |\n","|    time_elapsed    | 293      |\n","|    total_timesteps | 43129    |\n","| train/             |          |\n","|    actor_loss      | 0.49     |\n","|    critic_loss     | 0.11     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 43031    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.76     |\n","|    ep_rew_mean     | -0.76    |\n","| time/              |          |\n","|    episodes        | 15360    |\n","|    fps             | 146      |\n","|    time_elapsed    | 305      |\n","|    total_timesteps | 44958    |\n","| train/             |          |\n","|    actor_loss      | 0.462    |\n","|    critic_loss     | 0.066    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 44861    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.76     |\n","|    ep_rew_mean     | -0.76    |\n","| time/              |          |\n","|    episodes        | 16384    |\n","|    fps             | 146      |\n","|    time_elapsed    | 318      |\n","|    total_timesteps | 46775    |\n","| train/             |          |\n","|    actor_loss      | 0.33     |\n","|    critic_loss     | 0.112    |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 46678    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.79     |\n","|    ep_rew_mean     | -0.79    |\n","| time/              |          |\n","|    episodes        | 17408    |\n","|    fps             | 146      |\n","|    time_elapsed    | 331      |\n","|    total_timesteps | 48578    |\n","| train/             |          |\n","|    actor_loss      | 0.52     |\n","|    critic_loss     | 7.19     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 48480    |\n","---------------------------------\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed9bea39299f4b2a99c145b3d6abdf83","version_major":2,"version_minor":0},"text/plain":["Output()"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["SAC\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.9      |\n","|    ep_rew_mean     | -0.9     |\n","| time/              |          |\n","|    episodes        | 2048     |\n","|    fps             | 84       |\n","|    time_elapsed    | 200      |\n","|    total_timesteps | 17019    |\n","| train/             |          |\n","|    actor_loss      | 22.5     |\n","|    critic_loss     | 37.6     |\n","|    ent_coef        | 0.229    |\n","|    ent_coef_loss   | 0.677    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 16918    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 3.52     |\n","|    ep_rew_mean     | -2.52    |\n","| time/              |          |\n","|    episodes        | 4096     |\n","|    fps             | 84       |\n","|    time_elapsed    | 286      |\n","|    total_timesteps | 24282    |\n","| train/             |          |\n","|    actor_loss      | 3.86     |\n","|    critic_loss     | 2.25     |\n","|    ent_coef        | 0.373    |\n","|    ent_coef_loss   | 0.0166   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 24181    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 2.61     |\n","|    ep_rew_mean     | -1.61    |\n","| time/              |          |\n","|    episodes        | 6144     |\n","|    fps             | 84       |\n","|    time_elapsed    | 355      |\n","|    total_timesteps | 30039    |\n","| train/             |          |\n","|    actor_loss      | 3.59     |\n","|    critic_loss     | 25       |\n","|    ent_coef        | 0.343    |\n","|    ent_coef_loss   | -0.0269  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 29938    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 2.28     |\n","|    ep_rew_mean     | -1.28    |\n","| time/              |          |\n","|    episodes        | 8192     |\n","|    fps             | 84       |\n","|    time_elapsed    | 413      |\n","|    total_timesteps | 34793    |\n","| train/             |          |\n","|    actor_loss      | 2.58     |\n","|    critic_loss     | 1.06     |\n","|    ent_coef        | 0.386    |\n","|    ent_coef_loss   | -0.0254  |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 34692    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 2.26     |\n","|    ep_rew_mean     | -1.26    |\n","| time/              |          |\n","|    episodes        | 10240    |\n","|    fps             | 84       |\n","|    time_elapsed    | 465      |\n","|    total_timesteps | 39137    |\n","| train/             |          |\n","|    actor_loss      | 2.28     |\n","|    critic_loss     | 2.07     |\n","|    ent_coef        | 0.393    |\n","|    ent_coef_loss   | 0.0726   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 39036    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 2.09     |\n","|    ep_rew_mean     | -1.09    |\n","| time/              |          |\n","|    episodes        | 12288    |\n","|    fps             | 84       |\n","|    time_elapsed    | 517      |\n","|    total_timesteps | 43465    |\n","| train/             |          |\n","|    actor_loss      | 2.07     |\n","|    critic_loss     | 7.62     |\n","|    ent_coef        | 0.408    |\n","|    ent_coef_loss   | -0.112   |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 43364    |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 1.98     |\n","|    ep_rew_mean     | -0.98    |\n","| time/              |          |\n","|    episodes        | 14336    |\n","|    fps             | 84       |\n","|    time_elapsed    | 568      |\n","|    total_timesteps | 47751    |\n","| train/             |          |\n","|    actor_loss      | 1.77     |\n","|    critic_loss     | 5.28     |\n","|    ent_coef        | 0.411    |\n","|    ent_coef_loss   | 0.118    |\n","|    learning_rate   | 0.0003   |\n","|    n_updates       | 47650    |\n","---------------------------------\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"],"text/plain":[]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n","</pre>\n"],"text/plain":["\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<stable_baselines3.sac.sac.SAC at 0x7be1a035a380>"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Separate evaluation env\n","eval_env = gym.make('Minigolf-v1')\n","\n","ppo = PPO(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n","ddpg = DDPG(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n","sac = SAC(\"MlpPolicy\", env, verbose=1, policy_kwargs=dict(net_arch=[32]))\n","\n","print('PPO')\n","ppo.learn(total_timesteps=50000, log_interval=4, progress_bar=True)\n","\n","print('DDPG')\n","ddpg.learn(total_timesteps=50000, log_interval=1024, progress_bar=True)\n","\n","print('SAC')\n","sac.learn(total_timesteps=50000, log_interval=2048, progress_bar=True)"]},{"cell_type":"markdown","metadata":{"id":"u_bTprXqviBA"},"source":["Let us now evaluate the results of the training."]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1708271931287,"user":{"displayName":"Usevalad Milasheuski","userId":"09490051534564791418"},"user_tz":-60},"id":"6K570AdaviBA","outputId":"635e22a1-b8c7-4bc9-f83b-9c8636480d7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean reward: -2.23 Std reward: 1.0020035484523553 Num episodes: 100\n","Mean reward: -0.82 Std reward: 0.03861229196653691 Num episodes: 100\n","Mean reward: -1.01 Std reward: 0.06112580172368815 Num episodes: 100\n"]}],"source":["ppo_mean, ppo_std = evaluate(eval_env, ppo)\n","ddpg_mean, ddpg_std = evaluate(eval_env, ddpg)\n","sac_mean, sac_std = evaluate(eval_env, sac)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/albertometelli/rl-phd-2024/blob/main/02_gym_environment.ipynb","timestamp":1708262791505}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0152e8576ccb47fd94b0bbf9fa97fbfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0307778242b041df9f27210cb392e9a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1e21b38df3f40aab176bf252de36ed0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae12c35a83124142b2b0c6e0c8b7462e":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_0152e8576ccb47fd94b0bbf9fa97fbfd","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">51,126/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:58</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">430 it/s</span> ]\n</pre>\n","text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51,126/50,000 \u001b[0m [ \u001b[33m0:01:58\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m430 it/s\u001b[0m ]\n"},"metadata":{},"output_type":"display_data"}]}},"dca3cf7858494cdca59280e58e6ec4c7":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_a1e21b38df3f40aab176bf252de36ed0","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">49,983/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:05:40</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">145 it/s</span> ]\n</pre>\n","text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m49,983/50,000 \u001b[0m [ \u001b[33m0:05:40\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m145 it/s\u001b[0m ]\n"},"metadata":{},"output_type":"display_data"}]}},"ed9bea39299f4b2a99c145b3d6abdf83":{"model_module":"@jupyter-widgets/output","model_module_version":"1.0.0","model_name":"OutputModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_0307778242b041df9f27210cb392e9a4","msg_id":"","outputs":[{"data":{"text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">49,991/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:09:54</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">85 it/s</span> ]\n</pre>\n","text/plain":"\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m49,991/50,000 \u001b[0m [ \u001b[33m0:09:54\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m85 it/s\u001b[0m ]\n"},"metadata":{},"output_type":"display_data"}]}}}}},"nbformat":4,"nbformat_minor":0}
